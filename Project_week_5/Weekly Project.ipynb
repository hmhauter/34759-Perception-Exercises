{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Project 5 \n",
    "## Implementation of global registration \n",
    "### Task 1\n",
    "Today, your task is to implement a global registration algorithm.\n",
    "\n",
    "It should be able to roughly align two point clouds.\n",
    "Implement the global registration, and then try the following:\n",
    "\n",
    "1. Can you fit `r1.pcd` and `r2.pcd`?\n",
    "2. Can you fit `car1.ply` and `car2.ply`?\n",
    "The corresponding files are in the `global_registration` folder.\n",
    "\n",
    "\n",
    "### Task 2 (Challange)\n",
    "Challanges attempt either or both:\n",
    "- Implement local registration.\n",
    "\n",
    "- Attempt to reconstruct the car from the images in `car_challange` folder.\n",
    "\n",
    "You can use the notebooks from Monday as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for drawing\n",
    "# If you want it to be more clear set recolor=True\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    if(recolor):\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    if(transformation is not None):\n",
    "        source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL REGISTRATION\n",
    "# read pointcloud\n",
    "source = o3d.io.read_point_cloud(\"global_registration/r1.pcd\")\n",
    "target = o3d.io.read_point_cloud(\"global_registration/r2.pcd\")\n",
    "\n",
    "# Used for downsampling.\n",
    "voxel_size = 0.05\n",
    "source = source.voxel_down_sample(voxel_size=voxel_size)\n",
    "target = target.voxel_down_sample(voxel_size=voxel_size)\n",
    "source.estimate_normals()\n",
    "target.estimate_normals()\n",
    "\n",
    "# Show models side by side\n",
    "draw_registrations(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global registration with features\n",
    "def global_registration(source, target, vs, tr, rf):\n",
    "    point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "    radius_feature = vs * rf\n",
    "    f_source = o3d.pipelines.registration.compute_fpfh_feature(source, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=1000))\n",
    "    f_target = o3d.pipelines.registration.compute_fpfh_feature(target, o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=1000))\n",
    "    distance_threshold = vs * tr\n",
    "\n",
    "    corr_length = 0.9\n",
    "\n",
    "\n",
    "    c0 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(corr_length)\n",
    "    c1 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "    c2 = o3d.pipelines.registration.CorrespondenceCheckerBasedOnNormal(0.095)\n",
    "\n",
    "    checker_list = [c0, c1, c2]\n",
    "\n",
    "    ransac_result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source, target, \n",
    "        f_source, f_target, True,\n",
    "        distance_threshold,\n",
    "        point_to_point,\n",
    "        checkers = checker_list,\n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(10000000, 0.999))\n",
    "\n",
    "    return ransac_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ransac_result = global_registration(source, target, voxel_size, 1.5, 5)\n",
    "draw_registrations(source, target, ransac_result.transformation, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW WITH THE CAR DATA\n",
    "source = o3d.io.read_point_cloud(\"global_registration/car1.ply\")\n",
    "target = o3d.io.read_point_cloud(\"global_registration/car2.ply\")\n",
    "\n",
    "# Used for downsampling.\n",
    "voxel_size = 0.05\n",
    "source = source.voxel_down_sample(voxel_size=voxel_size)\n",
    "target = target.voxel_down_sample(voxel_size=voxel_size)\n",
    "\n",
    "source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                        max_nn=30),fast_normal_computation=True)\n",
    "target.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                        max_nn=30),fast_normal_computation=True)\n",
    "\n",
    "draw_registrations(source, target, None, True)\n",
    "ransac_result = global_registration(source, target, voxel_size,0.9, 2)\n",
    "draw_registrations(source, target, ransac_result.transformation, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHALLENGE TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement local registration\n",
    "\n",
    "def local_registration(source, target, threshold):\n",
    "    trans_init = np.asarray([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "    # evaluation = o3d.pipelines.registration.evaluate_registration(source, target, threshold, trans_init)\n",
    "    # print(evaluation)   \n",
    "    point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "    icp_result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, trans_init,\n",
    "        point_to_plane)\n",
    "    \n",
    "    return icp_result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegistrationResult with fitness=7.420168e-01, inlier_rmse=6.027961e-02, and correspondence_set size of 3532\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "# read pointcloud\n",
    "source = o3d.io.read_point_cloud(\"global_registration/r1.pcd\")\n",
    "target = o3d.io.read_point_cloud(\"global_registration/r2.pcd\")\n",
    "# Used for downsampling.\n",
    "voxel_size = 0.05\n",
    "source = source.voxel_down_sample(voxel_size=voxel_size)\n",
    "target = target.voxel_down_sample(voxel_size=voxel_size)\n",
    "# source.estimate_normals()\n",
    "# target.estimate_normals()\n",
    "source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                        max_nn=30),fast_normal_computation=True)\n",
    "target.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                        max_nn=30),fast_normal_computation=True)\n",
    "\n",
    "# Show models side by side\n",
    "draw_registrations(source, target)\n",
    "\n",
    "# START WITH GLOBAL REGISTRATION \n",
    "ransac_result = global_registration(source, target, voxel_size,0.9, 2)\n",
    "draw_registrations(source, target, ransac_result.transformation, True)\n",
    "source = source.transform(ransac_result.transformation)\n",
    "# DO LOCAL REGISTRATION\n",
    "threshold = 0.3\n",
    "res = local_registration(source, target, threshold)\n",
    "draw_registrations(source, target, res.transformation, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to reconstruct the car from the images in car_challange folder.\n",
    "# idea: read the images, match in batches (global plus local alignment), then downsample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPointCloud(path_color, path_depth, camera, T, voxel_size):\n",
    "    color = o3d.io.read_image(path_color)\n",
    "    depth = o3d.io.read_image(path_depth)\n",
    "    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        color, \n",
    "        depth, \n",
    "        convert_rgb_to_intensity = False)\n",
    "    pc = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "        rgbd_image, camera)\n",
    "    pc.transform(T)\n",
    "    pc = pc.voxel_down_sample(voxel_size=voxel_size)\n",
    "    pc.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                        max_nn=30),fast_normal_computation=True)\n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 1 of 1722\n",
      "Match 2 of 1722\n",
      "Match 3 of 1722\n",
      "Match 4 of 1722\n",
      "Match 5 of 1722\n",
      "Match 6 of 1722\n",
      "Match 7 of 1722\n",
      "Match 8 of 1722\n",
      "Match 9 of 1722\n",
      "Match 10 of 1722\n",
      "Match 11 of 1722\n",
      "Match 12 of 1722\n",
      "Match 13 of 1722\n",
      "Match 14 of 1722\n",
      "Match 15 of 1722\n",
      "Match 16 of 1722\n",
      "Match 17 of 1722\n",
      "Match 18 of 1722\n",
      "Match 19 of 1722\n",
      "--Downsampling--\n",
      "Match 20 of 1722\n",
      "Match 21 of 1722\n",
      "Match 22 of 1722\n",
      "Match 23 of 1722\n",
      "Match 24 of 1722\n",
      "Match 25 of 1722\n",
      "Match 26 of 1722\n",
      "Match 27 of 1722\n",
      "Match 28 of 1722\n",
      "Match 29 of 1722\n",
      "Match 30 of 1722\n",
      "Match 31 of 1722\n",
      "Match 32 of 1722\n",
      "Match 33 of 1722\n",
      "Match 34 of 1722\n",
      "Match 35 of 1722\n",
      "Match 36 of 1722\n",
      "Match 37 of 1722\n",
      "Match 38 of 1722\n",
      "Match 39 of 1722\n",
      "--Downsampling--\n",
      "Match 40 of 1722\n",
      "Match 41 of 1722\n",
      "Match 42 of 1722\n",
      "Match 43 of 1722\n",
      "Match 44 of 1722\n",
      "Match 45 of 1722\n",
      "Match 46 of 1722\n",
      "Match 47 of 1722\n",
      "Match 48 of 1722\n",
      "Match 49 of 1722\n",
      "Match 50 of 1722\n",
      "Match 51 of 1722\n",
      "Match 52 of 1722\n",
      "Match 53 of 1722\n",
      "Match 54 of 1722\n",
      "Match 55 of 1722\n",
      "Match 56 of 1722\n",
      "Match 57 of 1722\n",
      "Match 58 of 1722\n",
      "Match 59 of 1722\n",
      "--Downsampling--\n",
      "Match 60 of 1722\n",
      "Match 61 of 1722\n",
      "Match 62 of 1722\n",
      "Match 63 of 1722\n",
      "Match 64 of 1722\n",
      "Match 65 of 1722\n",
      "Match 66 of 1722\n",
      "Match 67 of 1722\n",
      "Match 68 of 1722\n",
      "Match 69 of 1722\n",
      "Match 70 of 1722\n",
      "Match 71 of 1722\n",
      "Match 72 of 1722\n",
      "Match 73 of 1722\n",
      "Match 74 of 1722\n",
      "Match 75 of 1722\n",
      "Match 76 of 1722\n",
      "Match 77 of 1722\n",
      "Match 78 of 1722\n",
      "Match 79 of 1722\n",
      "--Downsampling--\n",
      "Match 80 of 1722\n",
      "Match 81 of 1722\n",
      "Match 82 of 1722\n",
      "Match 83 of 1722\n",
      "Match 84 of 1722\n",
      "Match 85 of 1722\n",
      "Match 86 of 1722\n",
      "Match 87 of 1722\n",
      "Match 88 of 1722\n",
      "Match 89 of 1722\n",
      "Match 90 of 1722\n",
      "Match 91 of 1722\n",
      "Match 92 of 1722\n",
      "Match 93 of 1722\n",
      "Match 94 of 1722\n",
      "Match 95 of 1722\n",
      "Match 96 of 1722\n",
      "Match 97 of 1722\n",
      "Match 98 of 1722\n",
      "Match 99 of 1722\n",
      "--Downsampling--\n",
      "Match 100 of 1722\n",
      "Match 101 of 1722\n",
      "Match 102 of 1722\n",
      "Match 103 of 1722\n",
      "Match 104 of 1722\n",
      "Match 105 of 1722\n",
      "Match 106 of 1722\n",
      "Match 107 of 1722\n",
      "Match 108 of 1722\n",
      "Match 109 of 1722\n",
      "Match 110 of 1722\n",
      "Match 111 of 1722\n",
      "Match 112 of 1722\n",
      "Match 113 of 1722\n",
      "Match 114 of 1722\n",
      "Match 115 of 1722\n",
      "Match 116 of 1722\n",
      "Match 117 of 1722\n",
      "Match 118 of 1722\n",
      "Match 119 of 1722\n",
      "--Downsampling--\n",
      "Match 120 of 1722\n",
      "Match 121 of 1722\n",
      "Match 122 of 1722\n",
      "Match 123 of 1722\n",
      "Match 124 of 1722\n",
      "Match 125 of 1722\n",
      "Match 126 of 1722\n",
      "Match 127 of 1722\n",
      "Match 128 of 1722\n",
      "Match 129 of 1722\n",
      "Match 130 of 1722\n",
      "Match 131 of 1722\n",
      "Match 132 of 1722\n",
      "Match 133 of 1722\n",
      "Match 134 of 1722\n",
      "Match 135 of 1722\n",
      "Match 136 of 1722\n",
      "Match 137 of 1722\n"
     ]
    }
   ],
   "source": [
    "# recreate object pointcloud\n",
    "camera = o3d.camera.PinholeCameraIntrinsic(\n",
    "        o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)\n",
    "T = [[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]\n",
    "\n",
    "## PARAMETERS\n",
    "voxel_size = 0.5\n",
    "batch_size = 10\n",
    "jumps = 1\n",
    "threshold = 0.2\n",
    "trans_init = np.asarray([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "## READ FILES\n",
    "color_dir = 'car_challange/rgb/'\n",
    "depth_dir = 'car_challange/depth/'\n",
    "color_files = sorted(os.listdir(color_dir))\n",
    "depth_files = sorted(os.listdir(depth_dir))\n",
    "\n",
    "path_color = os.path.join(color_dir, color_files[0])\n",
    "path_depth = os.path.join(depth_dir, depth_files[0])\n",
    "match_pc = getPointCloud(path_color, path_depth, camera, T, voxel_size)\n",
    "pc_prev = match_pc\n",
    "\n",
    "images = []     # RGB images\n",
    "pcs = []        # pointclouds \n",
    "indx = 1\n",
    "\n",
    "while indx < 250:\n",
    "    # match PC with prev PC and then add matches onto each other\n",
    "# for indx in range(1, len(color_files)):    \n",
    "    path_color = os.path.join(color_dir, color_files[indx])\n",
    "    path_depth = os.path.join(depth_dir, depth_files[indx])\n",
    "    pc = getPointCloud(path_color, path_depth, camera, T, voxel_size)\n",
    "\n",
    "    ########### HERE THE open3d MAGIC HAPPENS ####################\n",
    "\n",
    "    # do global registration \n",
    "    ransac_result = global_registration(pc, pc_prev, voxel_size, 0.9, 2)\n",
    "    # transform \n",
    "    pc.transform(ransac_result.transformation)\n",
    "    # do local registration \n",
    "    ransac_result = local_registration(pc, pc_prev, threshold)\n",
    "    # downsample every x batches \n",
    "    pc.transform(ransac_result.transformation)\n",
    "    # match_pc = match_pc.voxel_down_sample(voxel_size=voxel_size)\n",
    "    # add matches but match with prev not total \n",
    "    pc_prev = pc\n",
    "    pc_prev.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                    max_nn=30),fast_normal_computation=True)\n",
    "    match_pc += pc\n",
    "    if(indx % ((jumps+1) * batch_size) == 0):\n",
    "        match_pc = match_pc.voxel_down_sample(voxel_size=voxel_size)\n",
    "        # o3d.visualization.draw_geometries([match_pc])\n",
    "        print(\"--Downsampling--\")\n",
    "    print(\"Match \" + str(indx) + \" of \" + str(1722))\n",
    "    indx += jumps\n",
    "\n",
    "    ##############################################################\n",
    "\n",
    "\n",
    "    # o3d.visualization.draw_geometries([pc])\n",
    "    # o3d.visualization.draw_geometries([match_pc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([match_pc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8667f60d411a4cdc3ab94fe9f445dccbfdc05ceaf135084130ce22b40d7acf37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
